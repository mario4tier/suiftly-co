# Control Plane Design

## Overview

The Suiftly control plane manages configuration distribution and status collection across all servers. It spans two repositories:

| Component | Repository | Runs On | API Port |
|-----------|------------|---------|----------|
| **Global Manager** | `~/suiftly-co` | Primary server (with PostgreSQL) | 22600 |
| **Local Manager** | `~/walrus` | All servers (including primary) | 22610-22613 |
| **VAULT files** | `~/walrus` | Generated by Global Manager, consumed by Local Manager | N/A |

**Port Allocation:** See [~/walrus/PORT_MAP.md](~/walrus/PORT_MAP.md) for the single source of truth on port assignments. Local Managers use ports 22610-22613 to support up to 4 instances in development for multi-server simulation.

**Primary Server (EU-West NetOps):**
```
~/suiftly-co/  → Global Manager, API, Webapp, PostgreSQL
~/walrus/      → Local Manager, HAProxy, keyserver, VAULT simulation
```

**Other Gateway Servers (multiple regions):**
```
~/walrus/      → Local Manager, HAProxy, keyserver (no suiftly-co)
```

---

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        Primary Server (EU-West NetOps)                      │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                         ~/suiftly-co                                  │  │
│  │  ┌─────────────────────────────────────────────────────────────────┐  │  │
│  │  │              Global Manager (daemon, 5-min cycle)               │  │  │
│  │  │                                                                 │  │  │
│  │  │  1. Aggregate HAProxy logs → usage metrics                      │  │  │
│  │  │  2. Calculate customer billing                                  │  │  │
│  │  │  3. Generate MA_VAULT (API keys + rate limits)                  │  │  │
│  │  │  4. Aggregate status from all Local Managers                    │  │  │
│  │  │  5. Cleanup old data                                            │  │  │
│  │  └─────────────────────────────────────────────────────────────────┘  │  │
│  │                              ↓                                        │  │
│  │                    PostgreSQL (source of truth)                       │  │
│  │                              ↓                                        │  │
│  │                    API Server → Webapp (UI)                           │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                 ↓                                           │
│                    MA_VAULT files (to /opt/syncf/data_tx/ma/)               │
│                                 ↓                                           │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                           ~/walrus                                    │  │
│  │  sync-files.py → distributes VAULT to all servers                     │  │
│  │  Local Manager → consumes VAULT, updates HAProxy                      │  │
│  │  HAProxy → enforces rate limits, logs requests                        │  │
│  │  Fluentd → ships logs back to PostgreSQL                              │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────────┘
                                  ↓
                        (rsync via sync-files.py)
                                  ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                      Other Gateway Servers (regions)                        │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                           ~/walrus                                    │  │
│  │  Local Manager → consumes VAULT, updates HAProxy                      │  │
│  │  HAProxy → enforces rate limits, logs requests                        │  │
│  │  Fluentd → ships logs back to PostgreSQL                              │  │
│  │  Status API → responds to GM health polls (pull-based)                │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## Data Flows

### 1. Configuration Distribution (Global → Local)

```
Database (customers, API keys, tiers)
           ↓
Global Manager (generates MA_VAULT)
           ↓
/opt/syncf/data_tx/ma/*.enc files
           ↓
sync-files.py (rsync to all servers)
           ↓
Local Manager (reads VAULT, updates HAProxy)
           ↓
HAProxy (enforces rate limits per customer)
```

### 2. Usage Collection (Local → Global)

```
Customer Request
       ↓
HAProxy (logs request with API key, bytes, latency)
       ↓
Syslog (UDP)
       ↓
Fluentd (1s batches)
       ↓
PostgreSQL (haproxy_logs table, TimescaleDB)
       ↓
Global Manager (aggregates into usage_hourly)
       ↓
Billing calculation
```

### 3. Status Reporting (Global polls Local)

```
Global Manager (periodic polling, e.g., every 60s)
       ↓
Fetches status from each Local Manager:
  GET http://server-a:22610/api/status
  GET http://server-b:22610/api/status
  ...
       ↓
PostgreSQL (server_status table)
       ↓
Global Manager (aggregates fleet health)
       ↓
API Server
       ↓
Webapp (admin dashboard)
```

**Pull-based design**: GM initiates all status queries. LMs are passive responders - they don't push status to GM. This simplifies networking (no inbound connections to GM needed from remote servers).

---

## Global Manager (This Repository)

Long-lived daemon process running on the primary database server. Handles all centralized operations.

### Responsibilities

1. **Metering** - Aggregates HAProxy logs into usage metrics
2. **Billing** - Calculates customer charges from usage data
3. **Vault Generation** - Generates MA_VAULT (customer API keys and rate limits)
4. **Status Aggregation** - Collects and aggregates status from all Local Managers
5. **Data Cleanup** - Removes old logs and maintains database health

### Key Characteristics

- **Long-lived daemon** - Runs continuously as a systemd service
- **Singleton** - Only one instance runs at a time (enforced by PostgreSQL advisory locks)
- **Idempotent** - Safe to run multiple times without side effects
- **Periodic** - Internal setInterval loop runs tasks every 5 minutes
- **Crash-safe** - Uses database transactions for atomicity
- **Resumable** - Picks up where it left off after failures
- **Graceful shutdown** - Handles SIGTERM/SIGINT properly

### Implementation

**Note:** Uses `pino` for logging - this is Fastify's built-in logger, same as the API server.

```typescript
// services/global-manager/src/index.ts

import { db } from '@suiftly/database'
import { acquireLock, releaseLock } from './lib/lock'
import { aggregateLogs } from './tasks/aggregate-logs'
import { calculateBills } from './tasks/calculate-bills'
import { generateMAVault } from './tasks/generate-ma-vault'
import { aggregateStatus } from './tasks/aggregate-status'
import { cleanup } from './tasks/cleanup'

// pino is Fastify's built-in logger (same stack as API server)
const logger = fastify.log  // or: import pino from 'pino'

const CONFIG = {
  LOCK_ID: 1001,  // PostgreSQL advisory lock
  RUN_INTERVAL_MS: 5 * 60 * 1000,  // 5 minutes
  DRY_RUN: process.env.DRY_RUN === 'true'
}

let isShuttingDown = false

// Main periodic task runner (runs each cycle)
async function runGlobalManager() {
  const startTime = Date.now()
  logger.info('Starting Global Manager cycle')

  let lockAcquired = false

  try {
    // Acquire exclusive lock (skip if another instance is running)
    lockAcquired = await acquireLock(CONFIG.LOCK_ID)
    if (!lockAcquired) {
      logger.warn('Another instance is running, skipping this cycle')
      return
    }

    // Run tasks in sequence (each is idempotent)
    await runWithMetrics('aggregate-logs', aggregateLogs)
    await runWithMetrics('calculate-bills', calculateBills)
    await runWithMetrics('generate-ma-vault', generateMAVault)
    await runWithMetrics('aggregate-status', aggregateStatus)
    await runWithMetrics('cleanup', cleanup)

    const duration = Date.now() - startTime
    logger.info({ duration }, 'Global Manager cycle completed')

  } catch (error) {
    logger.error({ error }, 'Global Manager cycle failed')
    // Don't throw - we want to continue running and try again next cycle
  } finally {
    if (lockAcquired) {
      await releaseLock(CONFIG.LOCK_ID)
    }
  }
}

// Scheduler loop (runs forever until shutdown)
async function scheduler() {
  logger.info({ intervalMs: CONFIG.RUN_INTERVAL_MS }, 'Scheduler started')

  while (!isShuttingDown) {
    try {
      await runGlobalManager()
    } catch (error) {
      logger.error({ error }, 'Unexpected error in scheduler')
    }

    if (!isShuttingDown) {
      logger.info(`Waiting ${CONFIG.RUN_INTERVAL_MS / 1000}s until next cycle`)
      await sleep(CONFIG.RUN_INTERVAL_MS)
    }
  }

  logger.info('Scheduler stopped')
}

// Helper: sleep with early exit on shutdown
function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => {
    const timeout = setTimeout(resolve, ms)
    const checkShutdown = setInterval(() => {
      if (isShuttingDown) {
        clearTimeout(timeout)
        clearInterval(checkShutdown)
        resolve()
      }
    }, 100)
  })
}

// Helper: track task metrics
async function runWithMetrics(taskName: string, task: () => Promise<void>) {
  const startTime = Date.now()
  logger.info({ task: taskName }, 'Starting task')

  try {
    await task()
    const duration = Date.now() - startTime

    await db.insert(worker_runs).values({
      worker_type: 'global-manager',
      task_name: taskName,
      status: 'success',
      duration_ms: duration,
      executed_at: new Date()
    })

    logger.info({ task: taskName, duration }, 'Task completed')
  } catch (error) {
    logger.error({ task: taskName, error }, 'Task failed')

    await db.insert(worker_runs).values({
      worker_type: 'global-manager',
      task_name: taskName,
      status: 'failed',
      error_message: error.message,
      executed_at: new Date()
    })

    throw error
  }
}

// Graceful shutdown handling
function setupShutdownHandlers() {
  const shutdown = async (signal: string) => {
    logger.info({ signal }, 'Shutdown signal received')
    isShuttingDown = true

    const maxWait = 30000
    const startWait = Date.now()
    while (Date.now() - startWait < maxWait) {
      await sleep(1000)
    }

    logger.info('Global Manager shutdown complete')
    process.exit(0)
  }

  process.on('SIGTERM', () => shutdown('SIGTERM'))
  process.on('SIGINT', () => shutdown('SIGINT'))
}

// Start the daemon
async function main() {
  logger.info('Global Manager daemon starting...')
  setupShutdownHandlers()
  await scheduler()
}

main().catch((error) => {
  logger.fatal({ error }, 'Fatal error in Global Manager')
  process.exit(1)
})
```

### Task: Aggregate Logs

```typescript
// services/global-manager/src/tasks/aggregate-logs.ts

export async function aggregateLogs() {
  // Get last processed timestamp
  const lastProcessed = await db.query.processing_state.findFirst({
    where: eq(processing_state.key, 'last_aggregated_log_timestamp')
  })

  const fromTimestamp = lastProcessed?.value || '2025-01-01T00:00:00Z'
  const toTimestamp = new Date().toISOString()

  // Aggregate into hourly buckets (idempotent via UPSERT)
  await db.execute(sql`
    INSERT INTO usage_hourly (hour, customer_id, service_type, request_count, bytes_in, bytes_out)
    SELECT
      date_trunc('hour', timestamp) as hour,
      customer_id,
      service_type,
      COUNT(*) as request_count,
      SUM(bytes_in) as bytes_in,
      SUM(bytes_out) as bytes_out
    FROM haproxy_logs
    WHERE timestamp > ${fromTimestamp}
      AND timestamp <= ${toTimestamp}
    GROUP BY hour, customer_id, service_type
    ON CONFLICT (hour, customer_id, service_type)
    DO UPDATE SET
      request_count = usage_hourly.request_count + EXCLUDED.request_count,
      bytes_in = usage_hourly.bytes_in + EXCLUDED.bytes_in,
      bytes_out = usage_hourly.bytes_out + EXCLUDED.bytes_out
  `)

  // Update last processed timestamp
  await db.insert(processing_state)
    .values({
      key: 'last_aggregated_log_timestamp',
      value: toTimestamp
    })
    .onConflictDoUpdate({
      target: processing_state.key,
      set: { value: toTimestamp, updated_at: new Date() }
    })
}
```

### Task: Generate MA_VAULT

```typescript
// services/global-manager/src/tasks/generate-ma-vault.ts
import { execSync } from 'child_process'

export async function generateMAVault() {
  // Get all active customers with their services and API keys
  const customers = await db.query.customers.findMany({
    where: eq(customers.status, 'active'),
    with: {
      api_keys: true,
      service_instances: true
    }
  })

  // Build MA_VAULT data structure (key-value format for kvcrypt)
  const vaultData: Record<string, string> = {}

  for (const customer of customers) {
    const sealService = customer.service_instances.find(s => s.service_type === 'seal')
    const tier = sealService?.tier || 'starter'

    const customerConfig = {
      api_keys: customer.api_keys.map(k => k.api_key_fp),
      tier,
      limits: getTierLimits(tier),
      status: customer.status
    }

    vaultData[`customer:${customer.customer_id}`] = JSON.stringify(customerConfig)
  }

  // Generate content hash for change detection
  const vaultContent = JSON.stringify(vaultData, null, 2)
  const vaultHash = crypto.createHash('sha256').update(vaultContent).digest('hex')

  // Check if this version already exists
  const existing = await db.query.vault_versions.findFirst({
    where: eq(vault_versions.content_hash, vaultHash)
  })

  if (!existing) {
    // New version - write to MA_VAULT using kvcrypt (from ~/walrus)
    for (const [key, value] of Object.entries(vaultData)) {
      execSync(`~/walrus/scripts/sync/kvcrypt.py put ma "${key}" '${value}'`, {
        stdio: 'pipe'
      })
    }

    await db.insert(vault_versions).values({
      version: Date.now(),
      content_hash: vaultHash,
      customer_count: customers.length,
      created_at: new Date()
    })

    logger.info({ hash: vaultHash, count: customers.length }, 'New MA_VAULT version generated')
    // sync-files.py (systemd timer in ~/walrus) distributes to all servers
  } else {
    logger.info({ hash: vaultHash }, 'MA_VAULT unchanged, skipping generation')
  }
}
```

### Task: Aggregate Status

```typescript
// services/global-manager/src/tasks/aggregate-status.ts

export async function aggregateStatus() {
  // Get latest status from all servers (reported by Local Managers)
  const serverStatuses = await db.query.server_status.findMany({
    where: gte(server_status.reported_at, sql`NOW() - INTERVAL '10 minutes'`)
  })

  // Calculate fleet health
  const totalServers = serverStatuses.length
  const healthyServers = serverStatuses.filter(s => s.status === 'healthy').length
  const degradedServers = serverStatuses.filter(s => s.status === 'degraded').length
  const unhealthyServers = serverStatuses.filter(s => s.status === 'unhealthy').length

  // Update fleet status
  await db.insert(fleet_status)
    .values({
      total_servers: totalServers,
      healthy_servers: healthyServers,
      degraded_servers: degradedServers,
      unhealthy_servers: unhealthyServers,
      updated_at: new Date()
    })
    .onConflictDoUpdate({
      target: fleet_status.id,
      set: {
        total_servers: totalServers,
        healthy_servers: healthyServers,
        degraded_servers: degradedServers,
        unhealthy_servers: unhealthyServers,
        updated_at: new Date()
      }
    })

  // Log any unhealthy servers
  const unhealthy = serverStatuses.filter(s => s.status === 'unhealthy')
  if (unhealthy.length > 0) {
    logger.warn({ servers: unhealthy.map(s => s.server_name) }, 'Unhealthy servers detected')
  }
}
```

---

## Local Manager (~/walrus Repository)

The Local Manager runs on every server and is documented in the walrus project. Key responsibilities:

1. **Consume VAULT** - Read MA_VAULT files distributed by sync-files.py
2. **Update HAProxy** - Apply rate limits and API key configurations
3. **Report Status** - Send health information to Global Manager
4. **Manage keyservers** - Coordinate Seal encryption services

**See ~/walrus project documentation for:**
- VAULT format specification (kvcrypt encrypted key-value store)
- Local Manager implementation
- HAProxy configuration templates
- Fluentd log shipping setup
- sync-files.py distribution mechanism

---

## Integration Points

### VAULT Interface

Global Manager writes VAULT using `kvcrypt.py` from ~/walrus:

```bash
# Write customer config to MA_VAULT
~/walrus/scripts/sync/kvcrypt.py put ma "customer:12345" '{"api_keys":["fp1","fp2"],"tier":"pro"}'

# Files created in /opt/syncf/data_tx/ma/
# sync-files.py distributes to all servers
```

**VAULT format is defined in ~/walrus** - this repository only produces data in that format.

### Status Reporting Interface

Global Manager polls Local Managers via HTTP GET:

```typescript
// GM polls: GET http://server-a:22610/api/status
// LM responds with:
interface ServerStatusResponse {
  server_name: string
  region: string
  status: 'healthy' | 'degraded' | 'unhealthy'
  haproxy_status: 'running' | 'stopped' | 'error'
  keyserver_status: 'running' | 'stopped' | 'error'
  vault_version: number
  last_vault_sync: string  // ISO timestamp
  metrics: {
    requests_per_second: number
    active_connections: number
    error_rate: number
  }
}
```

### Log Shipping Interface

Fluentd ships logs from HAProxy to PostgreSQL:

```sql
-- Expected log format (TimescaleDB hypertable)
INSERT INTO haproxy_logs (
  timestamp, customer_id, api_key_id, service_type,
  endpoint, method, status_code, bytes_in, bytes_out,
  request_time_ms, backend_time_ms, haproxy_server, region
) VALUES (...)
```

---

## Database Schema

### Tables Managed by Global Manager

```sql
-- Processing state tracking
CREATE TABLE processing_state (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Worker run history
CREATE TABLE worker_runs (
  id SERIAL PRIMARY KEY,
  worker_type TEXT NOT NULL,  -- 'global-manager'
  task_name TEXT NOT NULL,
  status TEXT NOT NULL,
  duration_ms INT,
  error_message TEXT,
  executed_at TIMESTAMPTZ DEFAULT NOW()
);

-- MA_VAULT versions
CREATE TABLE vault_versions (
  id SERIAL PRIMARY KEY,
  version BIGINT NOT NULL,
  content_hash TEXT NOT NULL UNIQUE,
  customer_count INT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Server status (reported by Local Managers)
CREATE TABLE server_status (
  server_name TEXT PRIMARY KEY,
  region TEXT NOT NULL,
  status TEXT NOT NULL,
  haproxy_status TEXT,
  keyserver_status TEXT,
  vault_version BIGINT,
  last_vault_sync TIMESTAMPTZ,
  metrics JSONB DEFAULT '{}',
  reported_at TIMESTAMPTZ DEFAULT NOW()
);

-- Fleet status (aggregated by Global Manager)
CREATE TABLE fleet_status (
  id INTEGER PRIMARY KEY DEFAULT 1,
  total_servers INT,
  healthy_servers INT,
  degraded_servers INT,
  unhealthy_servers INT,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Tables for Usage/Billing

See [CUSTOMER_SERVICE_SCHEMA.md](CUSTOMER_SERVICE_SCHEMA.md) for complete schema:
- `haproxy_logs` - TimescaleDB hypertable for raw logs
- `usage_hourly` - Aggregated usage metrics
- `billing_records` - Customer billing records

---

## Systemd Configuration

### Global Manager Service

```ini
# /etc/systemd/system/suiftly-global-manager.service
[Unit]
Description=Suiftly Global Manager (Long-Lived Daemon)
After=network.target postgresql.service
Requires=postgresql.service

[Service]
Type=simple
User=deploy
Group=deploy
WorkingDirectory=/var/www/global-manager

Environment="NODE_ENV=production"
Environment="DATABASE_URL=postgresql://deploy@localhost/suiftly_prod"

ExecStart=/usr/bin/node dist/index.js

Restart=always
RestartSec=10s

KillMode=mixed
KillSignal=SIGTERM
TimeoutStopSec=35s

MemoryMax=512M
CPUQuota=50%

StandardOutput=journal
StandardError=journal
SyslogIdentifier=suiftly-global-manager

PrivateTmp=yes
NoNewPrivileges=yes
ProtectSystem=strict
ProtectHome=yes
ReadWritePaths=/opt/syncf/data_tx

[Install]
WantedBy=multi-user.target
```

---

## Development & Testing

### Running Both Repositories Locally

```bash
# Terminal 1: Start suiftly-co (API, Webapp, DB)
cd ~/suiftly-co
./scripts/dev/start-dev.sh

# Terminal 2: Start walrus (Local Manager simulation)
cd ~/walrus
./scripts/dev/start-local-manager.sh --mock

# Terminal 3: Run Global Manager manually
cd ~/suiftly-co
npm run global-manager:dev
```

### E2E Test Flow

The walrus project provides VAULT simulation and multi-server mocking. To test the full control plane:

1. **Start suiftly-co services** (API, Webapp)
2. **Start walrus simulation** (mock HAProxy, keyservers, Local Manager)
3. **Trigger Global Manager cycle** (generates VAULT)
4. **Verify Local Manager receives VAULT** (walrus logs)
5. **Verify status flows back** (check server_status table)
6. **Verify UI displays status** (webapp admin dashboard)

```bash
# Run E2E control plane tests
cd ~/suiftly-co
npm run test:control-plane

# This script:
# 1. Starts both repos in test mode
# 2. Inserts test customer data
# 3. Runs Global Manager cycle
# 4. Verifies VAULT generation
# 5. Verifies status aggregation
# 6. Cleans up
```

### Mock Architecture

```
~/suiftly-co (this repo)           ~/walrus (mock mode)
┌─────────────────────┐            ┌─────────────────────┐
│ Global Manager      │───VAULT───→│ Local Manager       │
│ (real)              │            │ (real)              │
│                     │            │                     │
│ PostgreSQL          │←──status───│ Mock HAProxy        │
│ (real)              │            │ (simulated)         │
│                     │            │                     │
│ API Server          │←──logs─────│ Mock Fluentd        │
│ (real)              │            │ (simulated)         │
└─────────────────────┘            └─────────────────────┘
```

---

## Monitoring & Health Checks

### Admin Dashboard

Simple HTML dashboard on port 22600 (localhost only):

```typescript
// services/global-manager/src/admin-server.ts
fastify.get('/', async (req, reply) => {
  const lastRuns = await db.query.worker_runs.findMany({
    where: eq(worker_runs.worker_type, 'global-manager'),
    orderBy: desc(worker_runs.executed_at),
    limit: 20
  })

  const fleetStatus = await db.query.fleet_status.findFirst()

  return reply.type('text/html').send(`
    <h1>Control Plane Status</h1>
    <h2>Fleet Health</h2>
    <p>Healthy: ${fleetStatus.healthy_servers}/${fleetStatus.total_servers}</p>
    <h2>Recent Global Manager Runs</h2>
    <table>...</table>
  `)
})
```

### Health Check Endpoint

```typescript
// apps/api/src/routes/health.ts
router.get('/health/control-plane', async (req, res) => {
  const [lastRun, fleetStatus] = await Promise.all([
    db.query.worker_runs.findFirst({
      where: and(
        eq(worker_runs.worker_type, 'global-manager'),
        eq(worker_runs.status, 'success')
      ),
      orderBy: desc(worker_runs.executed_at)
    }),
    db.query.fleet_status.findFirst()
  ])

  const minutesSinceRun = (Date.now() - lastRun.executed_at.getTime()) / 60000
  const unhealthyRatio = fleetStatus.unhealthy_servers / fleetStatus.total_servers

  if (minutesSinceRun > 15 || unhealthyRatio > 0.5) {
    return res.status(503).send({ status: 'unhealthy' })
  }

  return res.send({
    status: 'healthy',
    global_manager_last_run: lastRun.executed_at,
    fleet: fleetStatus
  })
})
```

### Monitoring Commands

```bash
# Global Manager status
systemctl status suiftly-global-manager.service
journalctl -u suiftly-global-manager -f

# Recent runs
psql suiftly_prod -c "SELECT * FROM worker_runs ORDER BY executed_at DESC LIMIT 10;"

# Fleet status
psql suiftly_prod -c "SELECT * FROM fleet_status;"

# Server status (from Local Managers)
psql suiftly_prod -c "SELECT * FROM server_status ORDER BY reported_at DESC;"
```

---

## Security Considerations

1. **VAULT Encryption** - AES-256-GCM via kvcrypt (~/walrus)
2. **PostgreSQL Advisory Locks** - Prevent concurrent Global Manager execution
3. **Systemd Security** - ProtectSystem, PrivateTmp, limited permissions
4. **API Key Hashing** - Only fingerprints stored in VAULT, not raw keys
5. **Internal Network** - Status reporting over private network only
6. **Audit Trail** - All VAULT versions and configuration changes logged

---

## Disaster Recovery

### Global Manager Failure

- Advisory lock expires automatically
- Next cycle continues from last processed state
- Local Managers continue with cached VAULT

### Local Manager Failure

- HAProxy continues with last known config
- Status goes stale (detected by Global Manager)
- Alert generated for unhealthy server

### Database Failure

- Global Manager retries with exponential backoff
- Local Managers use cached VAULT
- Logs buffer in Fluentd until DB recovers

### Network Partition

- Local Managers operate independently
- VAULT updates queued until connectivity restored
- Status reporting resumes automatically

---

## Configuration Propagation & Verification

### Problem Statement

When a user changes their configuration (e.g., upgrades tier, adds API key, updates IP allowlist), we need to:

1. **Propagate changes** to all remote servers reliably
2. **Verify application** - confirm HAProxy and key-server have the correct config
3. **Handle different update cadences** - HAProxy is hot-reloadable, key-server requires restart
4. **Provide visibility** - users should be able to check if their changes are live

### Design Goals

| Goal | Description |
|------|-------------|
| **Consistency** | All servers eventually have identical configuration for a given user |
| **Verifiability** | Can confirm a specific user's config is applied on a specific server |
| **Minimal Disruption** | Key-server restarts are debounced (max once per 5 minutes) |
| **Observability** | Clear status reporting of propagation state per server |

---

### Configuration Versioning Strategy

We use **two-level versioning**:

```
┌─────────────────────────────────────────────────────────────────┐
│                    Global Config Version                        │
│                                                                 │
│  Version: 124                                                   │
│  Generated: 2025-01-15T10:30:00Z                               │
│  Hash: sha256:abc123...                                        │
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │              Per-User Change Tracking                    │  │
│  │                                                          │  │
│  │  customer:12345 → { lastModified: 124, tier: "pro" }    │  │
│  │  customer:67890 → { lastModified: 120, tier: "starter" }│  │
│  │  ...                                                     │  │
│  └──────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
```

**Global Version**: Monotonically increasing integer, incremented on each MA_VAULT generation.

**Per-User LastModified**: Records which global version last modified this user's config. Enables efficient per-user verification.

---

### HAProxy Configuration Verification

HAProxy map files can be queried via the **stats socket**. We leverage this for verification.

#### Map Files (Service-Specific)

Each service has its own config map. See [~/walrus/docs/HAPROXY_CONTROLS.md](~/walrus/docs/HAPROXY_CONTROLS.md) for complete format specification.

```
/etc/haproxy/conf.d/204-mseal_config.map     # Mainnet Seal
/etc/haproxy/conf.d/214-tseal_config.map     # Testnet Seal
/etc/haproxy/conf.d/203-mssfn_config.map     # Mainnet SSFN
/etc/haproxy/conf.d/213-tssfn_config.map     # Testnet SSFN
```

#### Map File Structure

```
# /etc/haproxy/conf.d/204-mseal_config.map
# Format: <customer_id> <header_hex>,<api_keys_hex>,<ip_filter_hex>,<extra_hex>

# Metadata (always present - stored as regular map entries)
__version__     124
__generated__   2025-01-15T10:30:00Z
__hash__        abc123

# Customer configurations (64-hex encoded, see HAPROXY_CONTROLS.md for field definitions)
42   0000002020000000,48656C7200000000,0000000000000000,0000000000000000
99   0000010060630000,AABBCCDD11223344,0000000000000000,0000000000000000
1337 0000040181820004,12345678ABCDEF01,C0A80001C0A80002,0000000000000000
```

#### Verification Methods

**Method 1: Version Check (Global)**
```bash
# Query map version via stats socket (example: mainnet seal)
echo "show map /etc/haproxy/conf.d/204-mseal_config.map __version__" | \
  socat stdio /run/haproxy/admin.sock
# Returns: __version__ 124
```

**Method 2: User Lookup (Per-User)**
```bash
# Check specific customer config (example: mainnet seal)
echo "show map /etc/haproxy/conf.d/204-mseal_config.map 42" | \
  socat stdio /run/haproxy/admin.sock
# Returns: 42 0000002020000000,48656C7200000000,0000000000000000,0000000000000000
```

**Method 3: HTTP Verification Endpoint (Remote)**

LM exposes an internal API that wraps the stats socket:

```
GET /api/haproxy/verify/{service}/{customerId}
Example: GET /api/haproxy/verify/mseal/42

Response:
{
  "found": true,
  "service": "mseal",
  "customerId": 42,
  "configHex": "0000002020000000,48656C7200000000,0000000000000000,0000000000000000",
  "mapVersion": 124,
  "serverName": "eu-west-1"
}
```

```
GET /api/haproxy/version/{service}
Example: GET /api/haproxy/version/mseal

Response:
{
  "service": "mseal",
  "version": 124,
  "generated": "2025-01-15T10:30:00Z",
  "hash": "abc123",
  "customerCount": 1500,
  "serverName": "eu-west-1"
}
```

---

### HAProxy Update Flow (Hot Reload)

HAProxy map files can be updated **without restart** using the stats socket. Each service has its own config map - the flow below is repeated for each service (mseal, tseal, mssfn, tssfn, etc.):

```
┌───────────────────────────────────────────────────────────────────────┐
│                        HAProxy Update Flow                            │
├───────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  1. GM generates new MA_VAULT (version 124)                          │
│                    ↓                                                  │
│  2. sync-files.py distributes to all servers                         │
│                    ↓                                                  │
│  3. LM detects new VAULT (via inotify or polling)                    │
│                    ↓                                                  │
│  4. LM parses VAULT, generates new map file content                  │
│                    ↓                                                  │
│  5. LM applies via stats socket using ATOMIC TRANSACTION:            │
│                                                                       │
│     # HAProxy supports atomic multi-entry transactions!              │
│     # See: haproxy.com/documentation/haproxy-runtime-api/reference/  │
│                                                                       │
│     # Example: mainnet seal config map                               │
│     MAP=/etc/haproxy/conf.d/204-mseal_config.map                     │
│     SOCK=/run/haproxy/admin.sock                                     │
│                                                                       │
│     # Step 1: Get current map state                                  │
│     echo "show map $MAP" | socat stdio $SOCK                         │
│                                                                       │
│     # Step 2: Start transaction (returns new version number)         │
│     echo "prepare map $MAP" | socat stdio $SOCK                      │
│     # Response: "New version created: 42"                            │
│                                                                       │
│     # Step 3: Apply all changes to the transaction version           │
│     # - Update metadata:                                             │
│     echo "set map @42 $MAP __version__ 124" | socat stdio $SOCK      │
│     # - For new entries:                                             │
│     echo "add map @42 $MAP 42 <config_hex>" | socat stdio $SOCK      │
│     # - For changed entries:                                         │
│     echo "set map @42 $MAP 99 <config_hex>" | socat stdio $SOCK      │
│     # - For removed entries:                                         │
│     echo "del map @42 $MAP 1337" | socat stdio $SOCK                 │
│                                                                       │
│     # Step 4: Commit transaction (atomic - all changes apply at once)│
│     echo "commit map @42 $MAP" | socat stdio $SOCK                   │
│                                                                       │
│  6. LM verifies via stats socket (check __version__ = expected)      │
│                    ↓                                                  │
│  7. LM reports to GM: { haproxyVersion: 124, status: "applied" }     │
│                                                                       │
└───────────────────────────────────────────────────────────────────────┘
```

**Key Points:**
- **Atomic transactions**: Use `prepare map` → changes → `commit map` for all-or-nothing updates
- **Never use `clear map`** - not hitless, leaves map empty during reload
- `commit map` applies all changes **instantly** - no partial states visible
- No HAProxy restart or reload needed
- Changes take effect **immediately** for new requests
- Existing connections continue with old config until complete

**Sources:** [HAProxy Runtime API Reference](https://www.haproxy.com/documentation/haproxy-runtime-api/reference/), [prepare map](https://www.haproxy.com/documentation/haproxy-runtime-api/reference/prepare-map/), [commit map](https://www.haproxy.com/documentation/haproxy-runtime-api/reference/commit-map/)

---

### Key-Server Update Flow (Debounced Restart)

Key-server changes require a restart which is potentially disruptive. We implement **debouncing** with a minimum 5-minute interval.

#### State Machine

```
                    ┌─────────────────────────────────┐
                    │           IDLE                  │
                    │   (no pending changes)          │
                    └─────────────────────────────────┘
                                   │
                                   │ Change arrives
                                   ▼
                    ┌─────────────────────────────────┐
                    │        PENDING_BATCH            │
      ┌───────────▶ │   (collecting changes)          │ ◀──────┐
      │             │   Timer: 5 min from last restart │       │
      │             └─────────────────────────────────┘        │
      │                            │                           │
      │                            │ Timer expires AND         │
      │                            │ 5 min since last restart  │
      │                            ▼                           │
      │             ┌─────────────────────────────────┐        │
      │             │         APPLYING                │        │
      │             │   (updating config, restarting) │        │
      │             └─────────────────────────────────┘        │
      │                            │                           │
      │   More changes             │ Success                   │
      │   arrive during            ▼                           │
      │   apply                   ┌─────────────────────────────┐
      └───────────────────────────│       COOLDOWN             │
                                  │   (5 min window)           │
                                  │   Changes → PENDING_BATCH  │
                                  └─────────────────────────────┘
                                               │
                                               │ 5 min elapsed, no pending
                                               ▼
                                  ┌─────────────────────────────┐
                                  │           IDLE              │
                                  └─────────────────────────────┘
```

#### Debounce Configuration

```typescript
interface KeyServerDebounceConfig {
  minRestartIntervalMs: 5 * 60 * 1000;  // 5 minutes
  maxBatchWaitMs: 10 * 60 * 1000;       // 10 minutes max wait for batching
  gracefulShutdownTimeoutMs: 30 * 1000; // 30 seconds for graceful shutdown
}
```

#### Implementation Sketch

```typescript
// In Local Manager
class KeyServerConfigManager {
  private pendingChanges: ConfigChange[] = [];
  private lastRestartAt: Date | null = null;
  private state: 'idle' | 'pending_batch' | 'applying' | 'cooldown' = 'idle';
  private debounceTimer: NodeJS.Timeout | null = null;

  async queueChange(change: ConfigChange): Promise<void> {
    this.pendingChanges.push(change);

    if (this.state === 'idle') {
      this.state = 'pending_batch';
      this.scheduleApply();
    }
    // If already pending/cooldown, changes accumulate automatically
  }

  private scheduleApply(): void {
    const timeSinceLastRestart = this.lastRestartAt
      ? Date.now() - this.lastRestartAt.getTime()
      : Infinity;

    const waitTime = Math.max(0, MIN_RESTART_INTERVAL - timeSinceLastRestart);

    this.debounceTimer = setTimeout(() => this.applyChanges(), waitTime);
  }

  private async applyChanges(): Promise<void> {
    this.state = 'applying';
    const changes = [...this.pendingChanges];
    this.pendingChanges = [];

    try {
      // 1. Generate new config file
      await this.generateKeyServerConfig(changes);

      // 2. Graceful restart
      await this.restartKeyServer();

      // 3. Verify health
      await this.waitForHealthy();

      this.lastRestartAt = new Date();
      this.state = 'cooldown';

      // Report success to GM
      await this.reportStatus({ keyServerVersion: this.currentVersion, status: 'applied' });

      // After cooldown, check if more changes accumulated
      setTimeout(() => {
        if (this.pendingChanges.length > 0) {
          this.state = 'pending_batch';
          this.scheduleApply();
        } else {
          this.state = 'idle';
        }
      }, MIN_RESTART_INTERVAL);

    } catch (error) {
      // On failure, retry with backoff
      this.pendingChanges = [...changes, ...this.pendingChanges];
      this.state = 'pending_batch';
      setTimeout(() => this.scheduleApply(), 60_000); // Retry in 1 min
    }
  }
}
```

---

### Which Changes Affect Which Component?

| Change Type               | HAProxy | Key-Server | Notes                               |
|---------------------------|---------|------------|-------------------------------------|
| API key added/revoked     | ✓       | ✗          | HAProxy validates API key           |
| Seal key added            | ✓       | ✓          | HAProxy routes, key-server decrypts |
| Seal key enabled/disabled | ✓       | ✗          | HAProxy blocks/allows traffic       |
| Package changed           | ✗       | ✓          | Key-server encryption config        |
| Tier change               | ✓       | ✗          | Rate limits only (HAProxy)          |
| Rate limit adjustment     | ✓       | ✗          | Only HAProxy enforces limits        |
| IP allowlist change       | ✓       | ✗          | HAProxy enforces IP restrictions    |
| Service enabled/disabled  | ✓       | ✗          | HAProxy blocks/allows traffic       |

**Key Insight:** Key-server restarts are rare - only triggered by:
1. New Seal key added (needs decryption capability)
2. Package configuration changed (encryption settings)

All access control (enable/disable, IP allowlist, rate limits) is enforced by HAProxy, making the 5-minute debounce window rarely a bottleneck.

---

### Propagation Status Tracking

#### Database Schema Additions

```sql
-- Track expected vs actual config per server
CREATE TABLE server_config_status (
  server_name TEXT NOT NULL,
  component TEXT NOT NULL,  -- 'haproxy' or 'keyserver'
  expected_version BIGINT NOT NULL,
  actual_version BIGINT,
  status TEXT NOT NULL,  -- 'synced', 'pending', 'applying', 'error'
  last_verified_at TIMESTAMPTZ,
  error_message TEXT,
  PRIMARY KEY (server_name, component)
);

-- Track per-customer propagation for fine-grained verification
CREATE TABLE customer_config_propagation (
  customer_id INTEGER NOT NULL,
  server_name TEXT NOT NULL,
  component TEXT NOT NULL,
  expected_version BIGINT NOT NULL,
  actual_version BIGINT,
  status TEXT NOT NULL,
  verified_at TIMESTAMPTZ,
  PRIMARY KEY (customer_id, server_name, component)
);
```

#### API Endpoint for Propagation Status

```typescript
// GET /api/config/propagation-status?customerId=12345
interface PropagationStatusResponse {
  customerId: number;
  expectedVersion: number;
  fullyPropagated: boolean;
  servers: {
    name: string;
    region: string;
    haproxy: {
      status: 'synced' | 'pending' | 'applying' | 'error';
      version: number | null;
      lastVerified: string;
    };
    keyserver: {
      status: 'synced' | 'pending' | 'applying' | 'cooldown' | 'error';
      version: number | null;
      nextApplyAt: string | null;  // For debounced changes
      lastVerified: string;
    };
  }[];
}
```

---

### Verification Flow (User-Initiated)

```
User: "Is my config change live?"
            │
            ▼
┌───────────────────────────────────────────────────────────────────────┐
│  1. API receives request: GET /api/config/propagation-status?cid=123 │
└───────────────────────────────────────────────────────────────────────┘
            │
            ▼
┌───────────────────────────────────────────────────────────────────────┐
│  2. GM queries all LMs in parallel (for each service):                │
│     GET http://server-a:22610/api/haproxy/verify/mseal/123           │
│     GET http://server-a:22610/api/keyserver/verify/123               │
│     GET http://server-b:22610/api/haproxy/verify/mseal/123           │
│     GET http://server-b:22610/api/keyserver/verify/123               │
│     ...                                                               │
└───────────────────────────────────────────────────────────────────────┘
            │
            ▼
┌───────────────────────────────────────────────────────────────────────┐
│  3. GM aggregates responses:                                          │
│                                                                       │
│     Server A (EU-West):                                              │
│       - HAProxy: version 124, customer found ✓                       │
│       - Key-server: version 124, customer found ✓                    │
│                                                                       │
│     Server B (US-East):                                              │
│       - HAProxy: version 124, customer found ✓                       │
│       - Key-server: version 120, pending restart (2 min remaining)   │
│                                                                       │
│     Server C (AP-South):                                             │
│       - HAProxy: version 122, sync in progress                       │
│       - Key-server: version 120, waiting for HAProxy first           │
│                                                                       │
└───────────────────────────────────────────────────────────────────────┘
            │
            ▼
┌───────────────────────────────────────────────────────────────────────┐
│  4. Return aggregated status to user                                  │
│                                                                       │
│  {                                                                    │
│    "customerId": 123,                                                │
│    "expectedVersion": 124,                                           │
│    "fullyPropagated": false,                                         │
│    "estimatedCompletionSeconds": 180,                                │
│    "servers": [...]                                                  │
│  }                                                                    │
└───────────────────────────────────────────────────────────────────────┘
```

---

### Implementation Phases

#### Phase 1: HAProxy Verification (Implement First)

1. Add version metadata to map files (`__version__`, `__generated__`, `__hash__`)
2. Add `lastModified` to per-customer config entries
3. LM endpoint: `GET /api/haproxy/version` - returns current map version
4. LM endpoint: `GET /api/haproxy/verify/{customerId}` - checks specific customer
5. GM aggregates status from all LMs
6. API endpoint: `GET /api/config/haproxy-status?customerId=...`

#### Phase 2: Key-Server Debouncing

1. Implement debounce state machine in LM
2. Add `keyserver_pending_changes` tracking
3. LM endpoint: `GET /api/keyserver/status` - includes pending/cooldown info
4. LM endpoint: `GET /api/keyserver/verify/{customerId}`
5. Extend propagation status to include key-server

#### Phase 3: User-Facing Status

1. API endpoint for full propagation status
2. Webapp UI showing propagation progress
3. Webhook/notification when propagation completes
4. Admin dashboard for fleet-wide config status

---

### Design Decisions

| Question | Decision |
|----------|----------|
| **Propagation timeout** | 15 minutes. After this, create admin notification (alarm). |
| **Partial propagation** | Continue propagating to remaining servers. Don't roll back successful ones. |
| **Key-server restart coordination** | Stagger restarts locally within each server. Only performed when two key-server processes are running and healthy on that server. No inter-region coordination - each server manages its own staggering independently. |
| **User notification** | No explicit notification. Service shows "Updating..." status during propagation. |
| **Emergency override** | Force version increase on-demand (useful for bug fixes). |

---

### Service Status During Propagation

The service status has **two independent dimensions**:

```
┌─────────────────────────────────────────────────────────────────┐
│                    Service Status Model                         │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Operational Status (mutually exclusive):                       │
│    • disabled - User has disabled the service                   │
│    • up       - Service is operational                          │
│    • down     - Service is experiencing issues                  │
│                                                                 │
│  Propagation Status (independent overlay):                      │
│    • (none)     - No changes pending                            │
│    • Updating... - Configuration change propagating             │
│                                                                 │
│  Combined display examples:                                     │
│    • "up"              - Normal operation                       │
│    • "up • Updating..."    - Working, config propagating        │
│    • "disabled"        - User disabled                          │
│    • "disabled • Updating..." - Disabled, config propagating    │
│    • "down"            - Service issue                          │
│    • "down • Updating..."  - Down, config propagating           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**UI Display:**
- Service routes show current status with "Updating..." indicator when propagating
- Dashboard shows aggregated status across all services
- "Updating..." clears automatically when propagation completes (all servers verified)
- After 15 minutes without completion, admin notification is raised but status continues showing "Updating..."

---

## Error Handling

All errors are reported via **admin notifications** in the database (`admin_notifications` table). This provides a centralized audit trail and enables alerting integrations.

### LM Unreachable

When GM cannot reach a Local Manager during configuration propagation:

1. **Skip and Continue** - GM skips the unreachable LM and continues with other servers
2. **Mark Server Status** - The server's `last_seen` timestamp becomes stale
3. **Retry Next Cycle** - Automatic retry on next polling cycle (default: 60 seconds)
4. **Admin Notification** - If server remains unreachable for >5 minutes, create notification (severity: `warning`)

```
┌─────────────────────────────────────────────────────┐
│  LM Unreachable Flow                                │
├─────────────────────────────────────────────────────┤
│                                                     │
│  GM ──────────────────────────────────────────────► │
│   │                                                 │
│   ├─► LM-1: POST /config ─────► Success ✓           │
│   │                                                 │
│   ├─► LM-2: POST /config ─────► Timeout (5s)        │
│   │                     │                           │
│   │                     └──► Skip, mark stale       │
│   │                                                 │
│   └─► LM-3: POST /config ─────► Success ✓           │
│                                                     │
│  Result: 2/3 servers updated                        │
│  LM-2 will receive config on next successful poll  │
│                                                     │
└─────────────────────────────────────────────────────┘
```

### HAProxy Socket Failure

When LM cannot communicate with the local HAProxy Runtime API:

1. **Retry with Backoff** - 3 attempts: immediate, +1s, +2s
2. **Abort Transaction** - If `prepare map` succeeded, explicitly `abort map`
3. **Report Failure** - Return error to GM with failure reason
4. **Admin Notification** - GM creates notification (severity: `error`) and marks server status as `error`

```typescript
// LM retry logic for HAProxy socket operations
async function executeHAProxyCommand(socket: string, command: string): Promise<string> {
  const maxRetries = 3;
  const backoffMs = [0, 1000, 2000];

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      if (attempt > 0) {
        await sleep(backoffMs[attempt]);
      }
      return await sendCommand(socket, command);
    } catch (error) {
      if (attempt === maxRetries - 1) {
        throw new HAProxySocketError(`Failed after ${maxRetries} attempts: ${error.message}`);
      }
    }
  }
}
```

### Version Mismatch After Commit

When verification shows version doesn't match expected value after successful commit:

1. **Log Warning** - Record mismatch details for debugging
2. **Re-attempt Next Cycle** - Do not retry immediately (avoid rapid loops)
3. **Increment Mismatch Counter** - Track for anomaly detection
4. **Admin Notification** - If mismatches persist across 3 cycles, create notification (severity: `warning`)

Possible causes:
- Race condition with another GM instance (should not happen in single-GM design)
- HAProxy reload between commit and verify
- Map file corruption or disk issues

### Error Response Format

All LM API errors return consistent JSON format:

```json
{
  "success": false,
  "error": {
    "code": "HAPROXY_SOCKET_TIMEOUT",
    "message": "HAProxy socket connection timed out after 5000ms",
    "retryable": true,
    "details": {
      "socket": "/run/haproxy/admin.sock",
      "command": "prepare map /etc/haproxy/conf.d/204-mseal_config.map",
      "attempt": 3
    }
  }
}
```

Error codes:
| Code | Description | Retryable |
|------|-------------|-----------|
| `HAPROXY_SOCKET_TIMEOUT` | Socket connection timeout | Yes |
| `HAPROXY_SOCKET_ERROR` | Socket communication error | Yes |
| `HAPROXY_TRANSACTION_FAILED` | Prepare/commit failed | Yes |
| `HAPROXY_VERSION_MISMATCH` | Version verification failed | Yes |
| `MAP_FILE_NOT_FOUND` | Map file doesn't exist | No |
| `INVALID_CONFIG_FORMAT` | Config data validation failed | No |
| `UNAUTHORIZED` | Request not from allowed IP | No |

---

## Security

### KVCrypt for VAULT Distribution

All VAULT data (customer configurations, API keys, secrets) **MUST** be encrypted using KVCrypt before distribution to servers.

**Requirements:**

1. **Encryption at Source** - GM encrypts VAULT payload before distribution
2. **Shared Key** - Single encryption key shared across all servers
3. **In-Transit Protection** - Even over TLS, VAULT data is KVCrypt-encrypted (defense in depth)

```
┌─────────────────────────────────────────────────────────────────┐
│  VAULT Distribution with KVCrypt                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  GM (NetOps)                                                    │
│   │                                                             │
│   ├─► Generate VAULT config (plaintext)                         │
│   │                                                             │
│   ├─► KVCrypt.encrypt(config, sharedKey) ──► ciphertext         │
│   │                                                             │
│   ├─► Distribute ciphertext to all LMs (via sync-files.py)      │
│   │                                                             │
│                                                                 │
│  LM (each server)                                               │
│   │                                                             │
│   └─► KVCrypt.decrypt(ciphertext, sharedKey) ──► plaintext      │
│       └─► Apply to HAProxy maps                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Implementation Notes:**

- KVCrypt library shared between GM and LM (`@suiftly/kvcrypt` package)
- Shared key provisioned to all servers during initial setup
- Failed decryption immediately rejects the request (no partial processing)

### LM API Firewall

Local Manager APIs are protected by IP allowlist firewall. Only IPs enumerated in `MA_VAULT` (Master Authority VAULT) are permitted to connect.

**Firewall Rules:**

1. **Default Deny** - All incoming connections to LM API port (default: 8080) blocked
2. **MA_VAULT Allowlist** - Only IPs listed in `MA_VAULT.allowed_ips` permitted
3. **Dynamic Updates** - Firewall rules update when MA_VAULT changes (via KVCrypt)
4. **Localhost Always Allowed** - `127.0.0.1` permitted for local diagnostics

```
┌─────────────────────────────────────────────────────────────────┐
│  LM API Firewall Configuration                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  MA_VAULT.allowed_ips:                                          │
│    - 10.0.1.10    # GM primary (eu-w1-1)                        │
│    - 10.0.1.11    # GM standby (eu-w1-2)                        │
│    - 10.0.2.10    # Admin jumphost                              │
│                                                                 │
│  iptables rules (auto-generated):                               │
│  ┌────────────────────────────────────────────────────────────┐ │
│  │ -A INPUT -p tcp --dport 8080 -s 127.0.0.1 -j ACCEPT        │ │
│  │ -A INPUT -p tcp --dport 8080 -s 10.0.1.10 -j ACCEPT        │ │
│  │ -A INPUT -p tcp --dport 8080 -s 10.0.1.11 -j ACCEPT        │ │
│  │ -A INPUT -p tcp --dport 8080 -s 10.0.2.10 -j ACCEPT        │ │
│  │ -A INPUT -p tcp --dport 8080 -j DROP                       │ │
│  └────────────────────────────────────────────────────────────┘ │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

**Security Properties:**

| Property | Implementation |
|----------|----------------|
| Authentication | IP allowlist (network-level) + KVCrypt signature |
| Authorization | All allowed IPs have full LM API access |
| Confidentiality | KVCrypt encryption + TLS transport |
| Integrity | KVCrypt signatures verify payload authenticity |
| Audit | All API calls logged with source IP and timestamp |

**Rejected Request Handling:**

- Firewall-blocked requests: silently dropped (no response)
- Invalid KVCrypt signature: HTTP 401 with `UNAUTHORIZED` error code
- All rejections logged to security audit log

---

## Future Enhancements

1. **Real-time Updates** - WebSocket push for instant rate limit changes
2. **Multi-region Aggregation** - Regional billing before global aggregation
3. **Anomaly Detection** - ML-based usage pattern analysis
4. **Live Subscriptions** - GraphQL subscriptions for dashboard updates
